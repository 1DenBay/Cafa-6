import streamlit as st
import torch
import torch.nn as nn
import pandas as pd
from Bio import SeqIO
from io import StringIO
import os

# --- AYARLAR VE SABÄ°TLER ---
st.set_page_config(
    page_title="BioTahmin AI - CNN Modeli",
    page_icon="ğŸ§¬",
    layout="wide"
)

# KlasÃ¶r yapÄ±na gÃ¶re model yolu: CAFA-6/models/best_cafa_model.pth -> CNN model kullanÄ±lacak
# os.path.join kullanÄ±yoruz ki Windows/Mac fark etmeden yolu bulsun.
MODEL_PATH = os.path.join("models", "best_cafa_model.pth")

# eÄŸitim parametreleri (Bunlar sabit)
NUM_LABELS = 1500
MAX_LEN = 1024
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu") #Â sistem neyi destekliyorsa ona gÃ¶re

# --- 2. MODEL MÄ°MARÄ°SÄ° (ResNet + LSTM) ---
class ResidualBlock(nn.Module): # modelin gÃ¶zÃ¼
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualBlock, self).__init__()
        # modelde kullanÄ±lan bÃ¼yÃ¼k filtreler (Kernel=9)
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=9, padding=4, stride=stride)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=9, padding=4)
        self.bn2 = nn.BatchNorm1d(out_channels)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),
                nn.BatchNorm1d(out_channels)
            )

    def forward(self, x):
        out = torch.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        return torch.relu(out)

class CafaModel(nn.Module): # modelin beyni
    def __init__(self, num_labels):
        super(CafaModel, self).__init__()
        # Harf SÃ¶zlÃ¼ÄŸÃ¼: 22 Karakter (20 asit + pad + unknown)
        self.embedding = nn.Embedding(22, 128)
        
        # CNN KatmanlarÄ± (ResNet) - Ã–zellik Ã§Ä±karÄ±cÄ±
        self.layer1 = ResidualBlock(128, 256, stride=1)
        self.layer2 = ResidualBlock(256, 512, stride=1)
        
        # LSTM KatmanÄ± (Zaman serisi/SÄ±ralama Ã¶ÄŸrenir)
        self.lstm = nn.LSTM(512, 128, batch_first=True, bidirectional=True)
        
        # Karar KatmanÄ± (Classifier)
        self.classifier = nn.Linear(256, num_labels)

    def forward(self, x):
        # 1. Embedding: Harfleri sayÄ±sal vektÃ¶rlere Ã§evir
        x = self.embedding(x).permute(0, 2, 1) # CNN formatÄ±na uygun hale getir
        
        # 2. CNN BloklarÄ±: Protein Ã¼zerindeki desenleri yakala
        x = self.layer1(x)
        x = self.layer2(x)
        
        # 3. LSTM: SÄ±ralamayÄ± ve baÄŸlamÄ± Ã¶ÄŸren
        x = x.permute(0, 2, 1)
        x, _ = self.lstm(x)
        
        # 4. Pooling: En Ã¶nemli Ã¶zellikleri seÃ§ (Max Pooling)
        x = torch.max(x, dim=1)[0]
        
        # 5. SonuÃ§: Hangi fonksiyon olduÄŸunu tahmin et
        return self.classifier(x)
    
    # --- 3. SÃ–ZLÃœK VE Ã–N Ä°ÅLEME (Preprocessing) ---
# Protein alfabesi (20 standart amino asit)
amino_acids = "ACDEFGHIKLMNPQRSTVWY"

# Harfleri sayÄ±ya Ã§eviren sÃ¶zlÃ¼k (A -> 1, C -> 2 ...)
vocab = {aa: i+1 for i, aa in enumerate(amino_acids)}
# Not: 0 numarasÄ± "Padding" (boÅŸluk doldurma) iÃ§in ayrÄ±lmÄ±ÅŸtÄ±r.
# 21 numarasÄ± "Bilinmeyen Harf" (Unknown) iÃ§in kullanÄ±lacaktÄ±r.

def encode_sequence(seq, max_len=1024):
    """
    Gelen protein harflerini (String) modelin anlayacaÄŸÄ± sayÄ±lara (Tensor) Ã§evirir.
    """
    # 1. Harf -> SayÄ± DÃ¶nÃ¼ÅŸÃ¼mÃ¼
    # EÄŸer listede olmayan bir harf gelirse (Ã¶r: 'X', 'B') onu 21 yap.
    encoded = [vocab.get(aa, 21) for aa in seq]
    
    # 2. Boyut Ayarlama (Sabit 1024 uzunluk)
    if len(encoded) > max_len:
        # Protein Ã§ok uzunsa 1024'ten sonrasÄ±nÄ± kes
        encoded = encoded[:max_len]
    else:
        # Protein kÄ±saysa sonuna 0 ekleyerek 1024'e tamamla (Padding)
        encoded += [0] * (max_len - len(encoded))
    
    # 3. PyTorch TensÃ¶rÃ¼ne Ã‡evirme
    # Model [Batch, Length] formatÄ± bekler. Tek bir protein olduÄŸu iÃ§in baÅŸÄ±na boyut ekliyoruz (unsqueeze).
    return torch.tensor(encoded, dtype=torch.long).unsqueeze(0)


# --- 4. MODELÄ° Ã–NBELLEÄE AL (Cache) ---
@st.cache_resource
def load_engine():
    """
    Modeli sadece bir kere yÃ¼kler ve hafÄ±zada tutar. 
    Her dÃ¼ÄŸmeye basÄ±ÅŸta tekrar yÃ¼kleyip zaman kaybetmez.
    """
    # Modeli oluÅŸtur (BoÅŸ beyin)
    model = CafaModel(NUM_LABELS).to(DEVICE)
    
    # Dosya kontrolÃ¼
    if not os.path.exists(MODEL_PATH):
        st.error(f"ğŸš¨ HATA: Model dosyasÄ± bulunamadÄ±!\nLÃ¼tfen ÅŸu dosyayÄ± kontrol edin: `{MODEL_PATH}`")
        return None
        
    try:
        # AÄŸÄ±rlÄ±klarÄ± yÃ¼kle (Dolu beyin)
        # map_location, GPU'da eÄŸitilen modeli CPU'da aÃ§abilmek iÃ§in gereklidir.
        state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
        model.load_state_dict(state_dict)
        model.eval() # EÄŸitim modunu kapat, sÄ±nav modunu aÃ§
        return model
    except Exception as e:
        st.error(f"Model yÃ¼klenirken teknik bir hata oluÅŸtu: {e}")
        return None


# --- 5. ARAYÃœZ TASARIMI (GÃ¶rÃ¼nÃ¼m) ---
st.title("ğŸ§¬ AI ile Protein Fonksiyon Tahmini (CNN-ResNet-LSTM) ")
st.markdown("""
**Deep Learning (CNN + ResNet + LSTM)** mimarisi kullanÄ±larak protein dizilimlerinden fonksiyon tahmini yapar.
(Bu model Kaggle yarÄ±ÅŸmasÄ±nda da kullanÄ±lmÄ±ÅŸtÄ±r.)
""")

# SayfayÄ± iki sÃ¼tuna bÃ¶l: Sol (Ayarlar), SaÄŸ (SonuÃ§lar)
col1, col2 = st.columns([1, 2])

with col1:
    # Sol Panel: Ayarlar ve Dosya YÃ¼kleme
    st.success(f"ğŸš€ Motor: CNN = **ResNet + LSTM**")
    st.info(f"âš¡ Cihaz: **{str(DEVICE).upper()}**")
    
    # GÃ¼ven EÅŸiÄŸi (Threshold): %20 altÄ±ndaki ihtimalleri gÃ¶sterme
    confidence = st.slider("GÃ¼ven EÅŸiÄŸi", 0.0, 1.0, 0.20, 0.01)

    # Dosya YÃ¼kleyici
    uploaded_file = st.file_uploader("Fasta DosyasÄ± SeÃ§in", type=["fasta", "txt"])

# --- 6. ANALÄ°Z MOTORU (Ä°ÅŸlem) ---
if uploaded_file:
    # Modeli Ã§aÄŸÄ±r
    model = load_engine()
    
    if model:
        # YÃ¼klenen dosyayÄ± oku
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        sequences = []
        ids = []
        # Biopython ile Fasta ayrÄ±ÅŸtÄ±rma
        for record in SeqIO.parse(stringio, "fasta"):
            ids.append(record.id)
            sequences.append(str(record.seq))
        
        with col2:
            # SaÄŸ Panel: SonuÃ§ EkranÄ±
            st.write(f"### ğŸ“‚ {len(sequences)} Protein YÃ¼klendi")
            
            # Analiz Butonu
            if st.button("ANALÄ°ZÄ° BAÅLAT", type="primary", use_container_width=True):
                progress_bar = st.progress(0)
                results = []
                
                with torch.no_grad(): # Tahmin yaparken gradyan hesaplama (HÄ±zlan)
                    for i, (prot_id, seq) in enumerate(zip(ids, sequences)):
                        # 1. Veriyi HazÄ±rla (SayÄ±ya Ã§evir)
                        input_tensor = encode_sequence(seq, MAX_LEN).to(DEVICE)
                        
                        # 2. Tahmin Et (Modeli Ã§alÄ±ÅŸtÄ±r)
                        output = torch.sigmoid(model(input_tensor))
                        probs = output.cpu().numpy()[0]
                        
                        # 3. SonuÃ§larÄ± Filtrele (EÅŸiÄŸi geÃ§enleri al)
                        found = False
                        for idx, score in enumerate(probs):
                            if score > confidence:
                                results.append({
                                    "Protein ID": prot_id,
                                    "GO Term Index": idx, # Etiket dosyasÄ± olmadÄ±ÄŸÄ± iÃ§in index numarasÄ±
                                    "OlasÄ±lÄ±k": score
                                })
                                found = True
                        
                        # Ä°lerleme Ã§ubuÄŸunu gÃ¼ncelle
                        progress_bar.progress((i + 1) / len(sequences))
                
                # 4. Tabloyu OluÅŸtur ve GÃ¶ster
                if results:
                    df = pd.DataFrame(results)
                    st.success("âœ… Analiz TamamlandÄ±")
                    
                    # Tabloyu "OlasÄ±lÄ±k" sÃ¼tununa gÃ¶re renklendir (Koyu mavi = YÃ¼ksek ihtimal)
                    st.dataframe(
                        df.style.format({"OlasÄ±lÄ±k": "{:.2%}"})
                          .background_gradient(subset=["OlasÄ±lÄ±k"], cmap="Blues"),
                        use_container_width=True
                    )
                    
                    # Excel Ä°ndirme Butonu
                    csv = df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        "ğŸ“¥ SonuÃ§larÄ± Excel (CSV) Olarak Ä°ndir",
                        csv,
                        "cnn_analiz_sonuclari.csv",
                        "text/csv"
                    )
                else:
                    st.warning("âš ï¸ Belirlenen eÅŸiÄŸin Ã¼zerinde bir sonuÃ§ bulunamadÄ±. EÅŸiÄŸi dÃ¼ÅŸÃ¼rmeyi deneyin.")

else:
    # Dosya yÃ¼klenmediyse saÄŸ tarafta bilgi mesajÄ± gÃ¶ster
    with col2:
        st.image("https://cdn-icons-png.flaticon.com/512/8834/8834080.png", width=150)
        
        st.markdown("""
Burada SunduÄŸumuz:  "SÃ¼rÃ¼kle - BÄ±rak" basitliÄŸidir. KullanÄ±cÄ± FASTA dosyasÄ±nÄ± atar, arkada dÃ¶nen matematiksel kaosu gÃ¶rmez, sadece sonucu gÃ¶rÃ¼r.
""")
        st.markdown("""
Veri GÃ¼venliÄŸi:  Veriler bir buluta gitmiyor. Her ÅŸey kendi bilgisayarÄ±nÄ±z iÃ§ide (Localhost) dÃ¶nÃ¼yor.
""")
        st.markdown("""
Ã‡Ä±ktÄ±:  Sonucunuzu Excel (CSV) formatÄ±nda indirilebilir, filtreleyebilir ve renklendirilmiÅŸ bir rapor olarak alabilirsiniz.
""")
        st.info("ğŸ‘ˆ Analiz iÃ§in soldaki panelden bir FASTA dosyasÄ± yÃ¼kleyiniz.")