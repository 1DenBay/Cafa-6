import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import os
import sys

# Kendi modÃ¼llerimizi Ã§aÄŸÄ±rmak iÃ§in yol ayarÄ±
# (Bu dosya src iÃ§inde olduÄŸu iÃ§in bir Ã¼st dizini gÃ¶rmesi lazÄ±m)
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data_processor import CafaProcessor, CafaDataset
from src.model import CafaCNN

def train():
    # --- 1. AYARLAR VE CÄ°HAZ SEÃ‡Ä°MÄ° ---
    # Mac (MPS), Nvidia (CUDA) veya Ä°ÅŸlemci (CPU) seÃ§imi 
    #Â bilgisayarÄ±n tÃ¼rÃ¼ne gÃ¶re en iyi performansÄ± alabilmek iÃ§in otomatik seÃ§im yapar.
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("ðŸš€ Cihaz: Apple M1/M2/M3 (MPS) - Turbo Modu Aktif!")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ðŸš€ Cihaz: NVIDIA GPU (CUDA)")
    else:
        device = torch.device("cpu")
        print("ðŸ¢ Cihaz: CPU (YavaÅŸ Mod)")

    # Hiperparametreler (Ayar DÃ¼ÄŸmeleri)
    BATCH_SIZE = 32      # Her seferde kaÃ§ protein incelenecek?
    LEARNING_RATE = 1e-3 # Hatalardan ne kadar hÄ±zlÄ± ders Ã§Ä±karÄ±lacak?
    EPOCHS = 5           # Kitap baÅŸtan sona kaÃ§ kez okunacak?
    NUM_LABELS = 1500    # KaÃ§ etiket tahmin edilecek?

    # --- 2. VERÄ°YÄ° HAZIRLA (GARSON) ---
    print("\nðŸ“Š Veriler YÃ¼kleniyor...")
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    processor = CafaProcessor(project_root=project_root, num_labels=NUM_LABELS)
    
    df_terms = processor.load_labels()
    seqs_dict = processor.load_fasta()
    
    # Ortak ID'leri bul
    common_ids = list(set(df_terms['EntryID']) & set(seqs_dict.keys()))
    print(f"ðŸ”— EÄŸitim iÃ§in {len(common_ids)} protein eÅŸleÅŸti.")
    
    # Dataset ve DataLoader
    train_dataset = CafaDataset(processor, common_ids, seqs_dict, df_terms)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)

    # --- 3. MODELÄ° KUR (BEYÄ°N) ---
    print("\nðŸ§  Model Ä°nÅŸa Ediliyor...")
    model = CafaCNN(num_labels=NUM_LABELS)
    model.to(device) # Modeli ekran kartÄ±na taÅŸÄ±

    # Hakem (Loss) ve AntrenÃ¶r (Optimizer)
    criterion = nn.BCEWithLogitsLoss() # Ã‡oklu etiket iÃ§in Ã¶zel hata Ã¶lÃ§er
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # --- 4. EÄžÄ°TÄ°M DÃ–NGÃœSÃœ (TRAINING LOOP) ---
    print(f"\nðŸ”¥ EÄŸitim BaÅŸlÄ±yor! ({EPOCHS} Tur)")
    
    for epoch in range(EPOCHS):
        model.train() # Modeli 'Ã–ÄŸrenme Modu'na al
        total_loss = 0
        
        for batch_idx, batch in enumerate(train_loader):
            # Verileri cihazÄ± taÅŸÄ± (CPU -> GPU/MPS)
            inputs = batch['input_ids'].to(device)
            labels = batch['labels'].to(device)
            
            # A. SIFIRLA: Ã–nceki turun artÄ±klarÄ±nÄ± temizle
            optimizer.zero_grad()
            
            # B. Ä°LERÄ° GÄ°T (Forward): Tahmin yap
            outputs = model(inputs)
            
            # C. HATAYI Ã–LÃ‡ (Loss): Ne kadar yanÄ±ldÄ±k?
            loss = criterion(outputs, labels)
            
            # D. GERÄ°YE BAK (Backward): HatanÄ±n kaynaÄŸÄ±nÄ± bul
            loss.backward()
            
            # E. GÃœNCELLE (Step): AÄŸÄ±rlÄ±klarÄ± dÃ¼zelt
            optimizer.step()
            
            total_loss += loss.item()
            
            # Her 100 pakette bir rapor ver
            if (batch_idx + 1) % 100 == 0:
                print(f"Epoch [{epoch+1}/{EPOCHS}], AdÄ±m [{batch_idx+1}/{len(train_loader)}], Hata: {loss.item():.4f}")
        
        # Bir tur bittiÄŸinde ortalama hatayÄ± yaz
        avg_loss = total_loss / len(train_loader)
        print(f"âœ… Epoch {epoch+1} TamamlandÄ±! Ortalama Hata: {avg_loss:.4f}")

    # --- 5. KAYDET ---
    save_path = os.path.join(project_root, "models", "cafa_model_v1.pth")
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    torch.save(model.state_dict(), save_path)
    print(f"\nðŸ’¾ Model kaydedildi: {save_path}")

if __name__ == "__main__":
    train()