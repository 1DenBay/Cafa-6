import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
import numpy as np
import os
import sys

# Kendi modÃ¼llerimizi Ã§aÄŸÄ±rmak iÃ§in yol ayarÄ±
# (Bu dosya src iÃ§inde olduÄŸu iÃ§in bir Ã¼st dizini gÃ¶rmesi lazÄ±m)
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.data_processor import CafaProcessor, CafaDataset
from src.model import CafaCNN

def train():
    # --- 1. AYARLAR VE CÄ°HAZ SEÃ‡Ä°MÄ° ---
    # Mac (MPS), Nvidia (CUDA) veya Ä°ÅŸlemci (CPU) seÃ§imi 
    #Â bilgisayarÄ±n tÃ¼rÃ¼ne gÃ¶re en iyi performansÄ± alabilmek iÃ§in otomatik seÃ§im yapar.
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("ðŸš€ Cihaz: Apple M1/M2/M3 (MPS) - Turbo Modu Aktif!")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
        print("ðŸš€ Cihaz: NVIDIA GPU (CUDA)")
    else:
        device = torch.device("cpu")
        print("ðŸ¢ Cihaz: CPU (YavaÅŸ Mod)")

    # Hiperparametreler (Ayar DÃ¼ÄŸmeleri)
    BATCH_SIZE = 32      # Her seferde kaÃ§ protein incelenecek?
    LEARNING_RATE = 0.0005 # Hatalardan ne kadar hÄ±zlÄ± ders Ã§Ä±karÄ±lacak?
    EPOCHS = 8           # Kitap baÅŸtan sona kaÃ§ kez okunacak?
    NUM_LABELS = 1500    # KaÃ§ etiket tahmin edilecek?
    THRESHOLD = 0.3      # %30'un Ã¼zerindeki ihtimalleri "1" kabul et (Kaggle iÃ§in kritik ayar)

    # --- 2. VERÄ°YÄ° HAZIRLA (GARSON) ---
    print("\nðŸ“Š Veriler YÃ¼kleniyor...")
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    processor = CafaProcessor(project_root=project_root, num_labels=NUM_LABELS)
    
    df_terms = processor.load_labels()
    seqs_dict = processor.load_fasta()
    
    # Ortak ID'leri bul
    all_ids = list(set(df_terms['EntryID']) & set(seqs_dict.keys()))
    print(f"ðŸ”— Toplam EÅŸleÅŸen Protein: {len(all_ids)}")
    
    # --- KRÄ°TÄ°K ADIM: Train / Validation AyrÄ±mÄ± ---
    # Verinin %20'sini saklÄ±yoruz (SÄ±nav iÃ§in)
    train_ids, val_ids = train_test_split(all_ids, test_size=0.2, random_state=42)
    print(f"ðŸ“˜ EÄŸitim Seti   : {len(train_ids)} protein")
    print(f"tc SÄ±nav Seti (Val): {len(val_ids)} protein")

    # Datasetleri oluÅŸtur
    train_dataset = CafaDataset(processor, train_ids, seqs_dict, df_terms)
    val_dataset = CafaDataset(processor, val_ids, seqs_dict, df_terms)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False) # SÄ±navda karÄ±ÅŸtÄ±rmaya gerek yok

    # --- 3. MODELÄ° KUR (BEYÄ°N) ---
    print("\nðŸ§  Model Ä°nÅŸa Ediliyor...")
    model = CafaCNN(num_labels=NUM_LABELS)
    model.to(device) # Modeli ekran kartÄ±na taÅŸÄ±

    # 1'leri bulmak, 0'larÄ± bulmaktan 10 kat daha Ã¶nemli olsun.
    # Bu sayede model "hepsine 0 basayÄ±m" tembelliÄŸinden vazgeÃ§er.
    pos_weight = torch.ones([NUM_LABELS]).to(device) * 10
    # Hakem (Loss) ve AntrenÃ¶r (Optimizer)
    criterion = nn.BCEWithLogitsLoss(model.parameters(), lr=LEARNING_RATE) # Ã‡oklu etiket iÃ§in Ã¶zel hata Ã¶lÃ§er
    
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # En iyi skoru takip etmek iÃ§in
    best_f1 = 0.0

    # --- 4. EÄžÄ°TÄ°M DÃ–NGÃœSÃœ (TRAINING LOOP) ---
    print(f"\nðŸ”¥ EÄŸitim BaÅŸlÄ±yor! ({EPOCHS} Tur)")
    
    for epoch in range(EPOCHS):
        model.train() # Modeli 'Ã–ÄŸrenme Modu'na al
        total_loss = 0
        
        for batch in train_loader:
            # Verileri cihazÄ± taÅŸÄ± (CPU -> GPU/MPS)
            inputs = batch['input_ids'].to(device)
            labels = batch['labels'].to(device)
            
            # A. SIFIRLA: Ã–nceki turun artÄ±klarÄ±nÄ± temizle
            optimizer.zero_grad()
            # B. Ä°LERÄ° GÄ°T (Forward): Tahmin yap
            outputs = model(inputs)
            # C. HATAYI Ã–LÃ‡ (Loss): Ne kadar yanÄ±ldÄ±k?
            loss = criterion(outputs, labels)
            # D. GERÄ°YE BAK (Backward): HatanÄ±n kaynaÄŸÄ±nÄ± bul
            loss.backward()
            # E. GÃœNCELLE (Step): AÄŸÄ±rlÄ±klarÄ± dÃ¼zelt
            optimizer.step()
            total_loss += loss.item()
            
            avg_train_loss = total_loss / len(train_loader)

        # B. SINAV (VALIDATION)
        # Dropout kapanÄ±r, model sadece bildiÄŸini okur.
        model.eval()
        val_loss = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad(): # HafÄ±zayÄ± yorma
            for batch in val_loader:
                inputs = batch['input_ids'].to(device)
                labels = batch['labels'].to(device)
                
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                
                # F1 Hesaplamak iÃ§in tahminleri al
                # Sigmoid ile 0-1 arasÄ±na Ã§ekiyoruz
                probs = torch.sigmoid(outputs)
                # EÅŸik deÄŸerinden (0.3) bÃ¼yÃ¼kse 1, kÃ¼Ã§Ã¼kse 0 yap
                preds = (probs > THRESHOLD).float()
                
                # Listeye ekle (CPU'ya alarak)
                all_preds.append(preds.cpu().numpy())
                all_labels.append(labels.cpu().numpy())

        avg_val_loss = val_loss / len(val_loader)
        
        # Listeleri birleÅŸtir
        all_preds = np.vstack(all_preds)
        all_labels = np.vstack(all_labels)
        
        # C. KARNE (F1 SCORE HESAPLA)
        # 'micro': Genel baÅŸarÄ±yÄ± Ã¶lÃ§er (Kaggle iÃ§in iyi bir gÃ¶sterge)
        val_f1 = f1_score(all_labels, all_preds, average='micro')
        
        print(f"Epoch [{epoch+1}/{EPOCHS}] -> "
              f"Train Loss: {avg_train_loss:.4f} | "
              f"Val Loss: {avg_val_loss:.4f} | "
              f"ðŸ… F1-Score: {val_f1:.4f}")

        # D. EN Ä°YÄ°YÄ° KAYDET
        if val_f1 > best_f1:
            best_f1 = val_f1
            save_path = os.path.join(project_root, "models", "best_cafa_model.pth")
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            torch.save(model.state_dict(), save_path)
            print(f"    ðŸ’¾ Yeni rekor! Model kaydedildi. (Skor: {val_f1:.4f})")